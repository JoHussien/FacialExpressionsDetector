{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoHussien/FacialExpressionsDetector/blob/main/GPUComputingAssignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPloixH_LOqc",
        "outputId": "c3cbb98a-9c94-47b4-a863-f1a9cd4b4e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-1awgxw55\n",
            "  Running command git clone -q https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-1awgxw55\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Question 1\n",
        "Write a program to perform matrix multiplication of any two floating-point matrices A and B. A and B do not need\n",
        "to be square matrices; however, their dimensions should be compatible. i.e, the number of columns of A has to be\n",
        "equal to the number of rows of B. A and B should be initialized to random values by the host, but their dimensions\n",
        "should be specified in the program using #define directives."
      ],
      "metadata": {
        "id": "mS1Y3vmz4BUd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication --> Sequential Implementation\n"
      ],
      "metadata": {
        "id": "WK-zQ9XtN714"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "#include <cstdlib>\n",
        "#include<iostream>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "\n",
        "#define  Height1 2000\n",
        "#define  Width1  2000\n",
        "#define  Height2 2000\n",
        "#define  Width2  2000\n",
        "using namespace std;\n",
        "\n",
        "void MatrixMulSequential(float* M, float* N,float* P)\n",
        "  {\n",
        "    \n",
        "\n",
        "    for(int i = 0; i < Height1; ++i)\n",
        "        for(int j = 0; j < Width2; ++j)\n",
        "            {   \n",
        "                float Pvalue = 0;\n",
        "                for(int k = 0; k < Width1; ++k)\n",
        "                  Pvalue += M[i * Width1 + k] * N[k * Width2+ j];\n",
        "                P[i*Width2+j]=Pvalue;\n",
        "            }\n",
        "  \n",
        "  }\n",
        "\n",
        "void intialize_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            //M[j+i*COLS] =rand()%256;\n",
        "             M[j+i*COLS] =j+i*COLS;\n",
        "      }\n",
        "  }\n",
        "}\n",
        "void Print_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            cout<<M[j+i*COLS]<<\" \";\n",
        "      }\n",
        "      cout<<endl;\n",
        "  }   \n",
        "}\n",
        "bool validation(){\n",
        "\n",
        "  if (Width1!=Height2){\n",
        "      cout<<\"There is an error in the dims of the matrices\"<<endl; \n",
        "      return 0;\n",
        "  }\n",
        "  return 1;\n",
        "  \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    srand(time(0));\n",
        "    \n",
        "    float *M,*N,*Pout;\n",
        "    \n",
        "    \n",
        "    if (!validation())\n",
        "        return 0;\n",
        "    \n",
        "\n",
        "    M=(float*) malloc(Width1*Height1*sizeof(float));\n",
        "    N=(float*) malloc(Width2*Height2*sizeof(float));\n",
        "    Pout=(float*) malloc(Width2*Height1*sizeof(float));\n",
        "    cout<<\"Size of M is: \"<<Height1<<\"x\"<<Width1<<endl;\n",
        "    cout<<\"Size of N is: \"<<Height2<<\"x\"<<Width2<<endl;\n",
        "\n",
        "    intialize_matrix(M,Height1,Width1);\n",
        "    intialize_matrix(N,Height2,Width2);\n",
        "    //cout<<\"M\"<<endl;\n",
        "    //Print_matrix(M,Height1,Width1);\n",
        "    //cout<<endl;\n",
        "    //cout<<\"N\"<<endl;\n",
        "    //Print_matrix(N,Height2,Width2);\n",
        "\n",
        "    cout<<endl;\n",
        "    clock_t start = clock();\n",
        "    MatrixMulSequential(M,N,Pout);\n",
        "    clock_t stop = clock();\n",
        "    double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "    cout<<\"Time taken to complete the computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "    //cout<<\"P\"<<endl;\n",
        "    // Print_matrix(Pout,Height1,Width2);\n",
        "  //  cout<<Pout[0]<<\" \"<<Pout[1];\n",
        "     //cout<<Pout[1999]<<\" \"<<Pout[1999];\n",
        "    //cout<<\"Finished Computing P matrix\"<<endl;\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "MHTBGvlCOpUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94547961-5c36-4c16-b28f-9479bc88b7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of M is: 2000x2000\n",
            "Size of N is: 2000x2000\n",
            "\n",
            "Time taken to complete the computation is: 65.8551 seconds.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication --> Parallel Implementation\n",
        "\n",
        "Your parallel implementation should use multiple\n",
        "2D blocks of threads but no shared memory. You program should print the performance of the sequential and\n",
        "parallel versions in GFLOPS. Provide results for each of the following block sizes: 16x16, and 32x32 (Teams of 3 should also report on block sizes of 4x4 and 8x8). What is the GPU utilization in each case? Note: for testing\n",
        "purposes, you try relatively small values for the dimensions of the matrices, but to provide timing results, A and B\n",
        "matrices have to be large enough to make parallelism useful (try values larger than 1000 for each dimension)."
      ],
      "metadata": {
        "id": "I2vBAR98OeyR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1venv_kCbegL",
        "outputId": "cba86eaa-6a1e-4303-97cc-d5e0fab7bd2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov  7 23:35:37 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!nvidia-smi\n",
        "\n",
        "\n",
        "%%cu\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "#include <cstdlib>\n",
        "#include<iostream>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "\n",
        "#define  Height1 2000\n",
        "#define  Width1  2000\n",
        "#define  Height2 2000\n",
        "#define  Width2  2000\n",
        "using namespace std;\n",
        "\n",
        "__global__\n",
        "void MatrixMulKernel(float* M, float* N,float* P)\n",
        "  {\n",
        "    \n",
        "    int Row = blockIdx.y*blockDim.y + threadIdx.y;\n",
        "    int Col = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    \n",
        "    float Pvalue = 0;\n",
        "    if (Row<Height1 && Col<Width2)\n",
        "      {\n",
        "        for (int k = 0; k < Width1; ++k){   \n",
        "          Pvalue += M[Row*Width1+k] * N[k*Width2+Col];\n",
        "        }\n",
        "        \n",
        "        P[Row*Width2+Col] = Pvalue;\n",
        "      }\n",
        "  }\n",
        "void MatrixMulOnDevice(float* M, float* N, float* P)\n",
        "\n",
        "  {\n",
        "  int size1 = Width1 * Height1 * sizeof(float);\n",
        "  int size2 = Width2 * Width1 * sizeof(float);\n",
        "  int size3 = Height1 * Width2 * sizeof(float);\n",
        "  \n",
        "  float *d_M, *d_N, *d_P;\n",
        "  cudaMalloc((void **)&d_M, size1);\n",
        "   cudaError_t err = cudaMalloc((void **) &d_M, size1);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMemcpy(d_M, M, size1, cudaMemcpyHostToDevice);\n",
        "     err = cudaMemcpy(d_M, M, size1, cudaMemcpyHostToDevice);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMalloc((void **)&d_N, size2);\n",
        "   err = cudaMalloc((void **) &d_N, size2);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMemcpy(d_N, N, size2, cudaMemcpyHostToDevice);\n",
        "  err =  cudaMemcpy(d_N, N, size2, cudaMemcpyHostToDevice);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMalloc((void **)&d_P, size3);\n",
        "    err = cudaMalloc((void **) &d_P, size3);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  \n",
        "  dim3 dimGrid(ceil(Width2/32.0), ceil(Height1/32.0), 1);\n",
        "\n",
        "  dim3 dimBlock(32,32, 1);\n",
        "  clock_t start = clock();\n",
        "  MatrixMulKernel<<<dimGrid, dimBlock>>>(d_M, d_N, d_P);\n",
        "  cudaDeviceSynchronize();\n",
        "  err= cudaDeviceSynchronize();\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  clock_t stop = clock();\n",
        "  double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "  cout<<\"Time taken to complete only the Kernel computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "  \n",
        "  cudaMemcpy(P, d_P, size3, cudaMemcpyDeviceToHost);\n",
        "     err=  cudaMemcpy(P, d_P, size3, cudaMemcpyDeviceToHost);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaFree(d_M); \n",
        "  cudaFree(d_N); cudaFree (d_P);\n",
        "  }\n",
        "\n",
        "void intialize_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            //M[j+i*COLS] =rand()%256;\n",
        "             M[j+i*COLS] =j+i*COLS;\n",
        "      }\n",
        "  }\n",
        "}\n",
        "void Print_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            cout<<M[j+i*COLS]<<\" \";\n",
        "      }\n",
        "      cout<<endl;\n",
        "  }   \n",
        "}\n",
        "bool validation(){\n",
        "\n",
        "  if (Width1!=Height2){\n",
        "      cout<<\"There is an error in the dims of the matrices\"<<endl; \n",
        "      return 0;\n",
        "  }\n",
        "  return 1;\n",
        "  \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    srand(time(0));\n",
        "    \n",
        "    float *M,*N,*Pout;\n",
        "    \n",
        "    \n",
        "    if (!validation())\n",
        "        return 0;\n",
        "    \n",
        "    cout<<\"Size of M is: \"<<Height1<<\"x\"<<Width1<<endl;\n",
        "    cout<<\"Size of N is: \"<<Height2<<\"x\"<<Width2<<endl;\n",
        "\n",
        "    M=(float*) malloc(Width1*Height1*sizeof(float));\n",
        "    N=(float*) malloc(Width2*Height2*sizeof(float));\n",
        "    Pout=(float*) malloc(Width2*Height1*sizeof(float));\n",
        "\n",
        "    intialize_matrix(M,Height1,Width1);\n",
        "    intialize_matrix(N,Height2,Width2);\n",
        "    cout<<\"M\"<<endl;\n",
        "  //  Print_matrix(M,Height1,Width1);\n",
        "    cout<<endl;\n",
        "    cout<<\"N\"<<endl;\n",
        "  //  Print_matrix(N,Height2,Width2);\n",
        "\n",
        "    cout<<endl;\n",
        "    clock_t start = clock();\n",
        "    MatrixMulOnDevice(M,N,Pout);\n",
        "    cudaDeviceSynchronize();\n",
        "    cudaError_t err1= cudaDeviceSynchronize();\n",
        "   if (err1!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err1), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "    clock_t stop = clock();\n",
        "    double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "    cout<<\"Time taken to complete the entire wrapper computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "\n",
        "    cout<<\"Finished Computing P matrix\"<<endl;\n",
        "\n",
        "    //cout<<\"P\"<<endl;\n",
        " // Print_matrix(Pout,Height1,Width2);\n",
        "  cout<<Pout[0]<<\" \"<<Pout[1];\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda3126d-e984-4129-d0c1-76e3d3f22765",
        "id": "qeLG4BrNlR4m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of M is: 2000x2000\n",
            "Size of N is: 2000x2000\n",
            "M\n",
            "\n",
            "N\n",
            "\n",
            "Time taken to complete only the Kernel computation is: 0.048754 seconds.\n",
            "Time taken to complete the entire wrapper computation is: 0.301577 seconds.\n",
            "Finished Computing P matrix\n",
            "5.32934e+12 5.32934e+12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speedup for 1000x500 * 500x1000 matrices\n",
        "Speedup = Time in Sequential / Time in Parallel\n",
        "\n",
        "speedup of kernel only = 1.77262/0.0015913 = 111x times speedup\n",
        "\n",
        "speedup of whole wrapper function = 1.77262/0.308345 = 6x times speedup"
      ],
      "metadata": {
        "id": "Q7zsUFsJBDj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speedup for 1000x1000 matrices\n",
        "Speedup = Time in Sequential / Time in Parallel\n",
        "\n",
        "speedup of kernel only = 3.54652/0.031297 = 113x times speedup\n",
        "\n",
        "speedup of whole wrapper function = 3.54652/0.323412 = 11x times speedup"
      ],
      "metadata": {
        "id": "t6VRD9M7NxmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 Tiling and Shared Memory\n",
        "\n",
        "Repeat Task 1 using shared memory (and tiling) for the parallel implementation. \n"
      ],
      "metadata": {
        "id": "4BrlhkHxuQqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "#include <cstdlib>\n",
        "#include<iostream>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "\n",
        "#define  Height1 2000\n",
        "#define  Width1  2000\n",
        "#define  Height2 2000\n",
        "#define  Width2  2000\n",
        "#define TILE_WIDTH 16\n",
        "using namespace std;\n",
        "\n",
        "__global__\n",
        "void MatrixMulKernel(float* M, float* N,float* P)\n",
        "  {\n",
        "    \n",
        "        \n",
        "    \n",
        "    \n",
        "    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];\n",
        "    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];\n",
        "   \n",
        "    int bx=blockIdx.x;int by=blockIdx.y;\n",
        "    int tx=threadIdx.x;int ty=threadIdx.y; \n",
        "    int Row = by*TILE_WIDTH + ty;\n",
        "    int Col = bx*TILE_WIDTH + tx;\n",
        "    \n",
        "    float Pvalue = 0;\n",
        "    for(int ph=0;ph < ceil(Width1/(float)TILE_WIDTH);++ph)\n",
        "      {      \n",
        "        if(Row<Height1 && (ph*TILE_WIDTH+tx)<Width1)\n",
        "          Mds[ty][tx]=M[Row*Width1+ph*TILE_WIDTH+tx];\n",
        "    \n",
        "       if((ph*TILE_WIDTH+ty)<Height2 && Col< Width2)\n",
        "          Nds[ty][tx]=N[(ph*TILE_WIDTH+ty)*Width2+Col];\n",
        "      \n",
        "        __syncthreads();\n",
        "     \n",
        "        for (int k = 0; k < TILE_WIDTH; ++k){  \n",
        "            Pvalue += Mds[ty][k] * Nds[k][tx]; \n",
        "          }\n",
        "       \n",
        "       __syncthreads();\n",
        "      }\n",
        " \n",
        "   if (Row<Height1 && Col<Width2){\n",
        "      P[Row*Width2+Col] = Pvalue;\n",
        "   }\n",
        "   \n",
        "   \n",
        "\n",
        "    \n",
        "  }\n",
        "   \n",
        "void MatrixMulOnDevice(float* M, float* N, float* P)\n",
        "\n",
        "  {\n",
        "  int size1 = Width1 * Height1 * sizeof(float);\n",
        "  int size2 = Width2 * Width1 * sizeof(float);\n",
        "  int size3 = Height1 * Width2 * sizeof(float);\n",
        "  \n",
        "  float *d_M, *d_N, *d_P;\n",
        "  cudaMalloc((void **)&d_M, size1);\n",
        "  cudaError_t err = cudaMalloc((void **) &d_M, size1);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMemcpy(d_M, M, size1, cudaMemcpyHostToDevice);\n",
        "   err = cudaMemcpy(d_M, M, size1, cudaMemcpyHostToDevice);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMalloc((void **)&d_N, size2);\n",
        "   err = cudaMalloc((void **)&d_N, size2);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMemcpy(d_N, N, size2, cudaMemcpyHostToDevice);\n",
        "    err = cudaMemcpy(d_N, N, size2, cudaMemcpyHostToDevice);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "   \n",
        "  cudaMalloc((void **)&d_P, size3);\n",
        "     err = cudaMalloc((void **)&d_P, size3);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "\n",
        "  dim3 dimGrid(ceil(Width2/(float)TILE_WIDTH), ceil(Height1/(float)TILE_WIDTH), 1);\n",
        "  dim3 dimBlock(TILE_WIDTH,TILE_WIDTH, 1);\n",
        "  \n",
        "  clock_t start = clock();\n",
        "  MatrixMulKernel<<<dimGrid, dimBlock>>>(d_M, d_N, d_P);\n",
        "  cudaDeviceSynchronize();\n",
        "       err =  cudaDeviceSynchronize();\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  clock_t stop = clock();\n",
        "  double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "  cout<<\"Time taken to complete only the Kernel computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "    \n",
        "  cudaMemcpy(P, d_P, size3, cudaMemcpyDeviceToHost);\n",
        "        err = cudaMemcpy(P, d_P, size3, cudaMemcpyDeviceToHost);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "   \n",
        "  cudaFree(d_M); cudaFree(d_N); cudaFree (d_P);\n",
        "  }\n",
        "\n",
        "void intialize_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            //M[j+i*COLS] =rand()%256;\n",
        "             M[j+i*COLS] =j+i*COLS;\n",
        " \n",
        "\n",
        "      }\n",
        "  }\n",
        "}\n",
        "void Print_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            cout<<M[j+i*COLS]<<\" \";\n",
        "      }\n",
        "      cout<<endl;\n",
        "  }   \n",
        "}\n",
        "bool validation(){\n",
        "\n",
        "  if (Width1!=Height2){\n",
        "      cout<<\"There is an error in the dims of the matrices\"<<endl; \n",
        "      return 0;\n",
        "  }\n",
        "  return 1;\n",
        "  \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    srand(time(0));\n",
        "    \n",
        "    float *M,*N,*Pout;\n",
        "    \n",
        "    \n",
        "    if (!validation())\n",
        "        return 0;\n",
        "        \n",
        "    cout<<\"Size of M is: \"<<Height1<<\"x\"<<Width1<<endl;\n",
        "    cout<<\"Size of N is: \"<<Height2<<\"x\"<<Width2<<endl;\n",
        "\n",
        "    M=(float*) malloc(Width1*Height1*sizeof(float));\n",
        "    N=(float*) malloc(Width2*Height2*sizeof(float));\n",
        "    Pout=(float*) malloc(Width2*Height1*sizeof(float));\n",
        "\n",
        "    intialize_matrix(M,Height1,Width1);\n",
        "    intialize_matrix(N,Height2,Width2);\n",
        "    //cout<<\"M\"<<endl;\n",
        "    //Print_matrix(M,Height1,Width1);\n",
        "    cout<<endl;\n",
        "    //cout<<\"N\"<<endl;\n",
        "    //Print_matrix(N,Height2,Width2);\n",
        "\n",
        "    cout<<endl;\n",
        "    clock_t start = clock();\n",
        "    MatrixMulOnDevice(M,N,Pout);\n",
        "    cudaDeviceSynchronize();\n",
        "       cudaError_t err1 =   cudaDeviceSynchronize();\n",
        "   if (err1!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err1), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "    clock_t stop = clock();\n",
        "    double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "    cout<<\"Time taken to complete the entire wrapper computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "\n",
        "    cout<<\"Finished Computing P matrix\"<<endl;\n",
        "//    cout<<\"P\"<<endl;\n",
        "  // Print_matrix(Pout,Height1,Width2);\n",
        "\n",
        "\n",
        " cout<<Pout[0]<<\" \"<<Pout[1];\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "140f180d-fe11-4b9f-cb44-60e900af044e",
        "id": "9mr57klpuQqn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of M is: 2000x2000\n",
            "Size of N is: 2000x2000\n",
            "\n",
            "\n",
            "Time taken to complete only the Kernel computation is: 0.047152 seconds.\n",
            "Time taken to complete the entire wrapper computation is: 0.29152 seconds.\n",
            "Finished Computing P matrix\n",
            "5.32934e+12 5.32934e+12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speedup for 1000x500 * 500x1000 matrices\n",
        "Speedup = Time in Sequential / Time in Parallel\n",
        "\n",
        "speedup of kernel only = 1.77262/0.003176 = 558x times speedup\n",
        "\n",
        "speedup of whole wrapper function = 1.77262/0.281566 = 6x times speedup"
      ],
      "metadata": {
        "id": "5Lnh2DO3ECy8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speedup for 1000x1000 matrices\n",
        "Speedup = Time in Sequential / Time in Parallel\n",
        "\n",
        "speedup of kernel only = 3.54652/0.00624 = 568x times speedup\n",
        "\n",
        "speedup of whole wrapper function = 3.54652/0.292596 = 12x times speedup"
      ],
      "metadata": {
        "id": "-HwVUQktECy9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 --> Different Thread Granularities (Done coding 💃 💃)\n",
        "\n",
        "Repeat Task 2 with thread granularities of 2 and 4. i.e, each thread block will compute 2 or 4 elements in the\n",
        "output matrix (Each block of threads will be responsible for computing 2 or 4 output tiles). Teams of 3 should also\n",
        "report on thread granularity of 8.\n",
        "\n"
      ],
      "metadata": {
        "id": "GZYmo4XROqjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " %%cu\n",
        "#include<cuda.h>\n",
        "#include<stdio.h>\n",
        "#include <cstdlib>\n",
        "#include<iostream>\n",
        "#include <time.h>\n",
        "\n",
        "\n",
        "\n",
        "#define  Height1 2000\n",
        "#define  Width1  2000\n",
        "#define  Height2 2000\n",
        "#define  Width2  2000\n",
        "#define TILE_WIDTH 16\n",
        "#define granularity 8\n",
        "using namespace std;\n",
        "\n",
        "__global__\n",
        "void MatrixMulKernel(float* M, float* N,float* P)\n",
        "  {\n",
        "    \n",
        "        \n",
        "    \n",
        "      \n",
        "    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH*granularity];\n",
        "    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH*granularity];\n",
        "   \n",
        "    int bx=blockIdx.x;\n",
        "   \n",
        "    int by=blockIdx.y;\n",
        "    int tx=threadIdx.x;\n",
        "    int ty=threadIdx.y; \n",
        "    \n",
        "    int Row = by*TILE_WIDTH + ty;\n",
        "    int Col = bx*TILE_WIDTH + tx;\n",
        "\n",
        "    int Col1=Col*granularity;\n",
        "    int tx1=tx*granularity;\n",
        "    \n",
        "\n",
        "    \n",
        "    float Pvalue[granularity];\n",
        "   for (int i=0;i<granularity;i++){\n",
        "      Pvalue[i]=0;\n",
        " }\n",
        "\n",
        "    for(int ph=0;ph < ceil(Width1/((float)TILE_WIDTH));++ph)\n",
        "      {     \n",
        "          if((Row)<Height1 && (ph*TILE_WIDTH+tx)<Width1)\n",
        "          {\n",
        "                        Mds[ty][tx]=M[(Row)*Width1+ph*TILE_WIDTH+tx];\n",
        "                        \n",
        "          }\n",
        "          for(int j =0;j<granularity;j++)\n",
        "            {\n",
        "                      \n",
        "                      if((ph*TILE_WIDTH+ty)<Height2 && (Col1+j)< Width2){\n",
        "                        Nds[ty][tx1+j]=N[(ph*TILE_WIDTH+ty)*Width2+(Col1+j)];\n",
        "                      \n",
        "                    }\n",
        "                      \n",
        "                    \n",
        "                  __syncthreads();\n",
        "            \n",
        "                      for (int k = 0; k < TILE_WIDTH; ++k){  \n",
        "                          Pvalue[j] += Mds[ty][k] * Nds[k][tx1+j];\n",
        "                         \n",
        "                        }\n",
        "               \n",
        "     \n",
        "       __syncthreads();\n",
        "            }\n",
        "      }\n",
        "    for(int j =0;j<granularity;j++)\n",
        "        {\n",
        "          if (Row<Height1 && Col1+j<Width2){\n",
        "              //if(j==0) //in order not repeat the same threads\n",
        "              //printf(\"tx:%d,ty:%d\\n\",tx,ty); //to check how many thread working\n",
        "            P[Row*Width2+Col1+j] = Pvalue[j];\n",
        "          }\n",
        "    \n",
        "        }\n",
        "      \n",
        "\n",
        "   \n",
        "    \n",
        "  }\n",
        "   \n",
        "void MatrixMulOnDevice(float* M, float* N, float* P)\n",
        "\n",
        "  {\n",
        "  int size1 = Width1 * Height1 * sizeof(float);\n",
        "  int size2 = Width2 * Width1 * sizeof(float);\n",
        "  int size3 = Height1 * Width2 * sizeof(float);\n",
        "  \n",
        "  float *d_M, *d_N, *d_P;\n",
        "  cudaMalloc((void **)&d_M, size1);\n",
        "  cudaError_t err = cudaMalloc((void **)&d_M, size1);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMemcpy(d_M, M, size1, cudaMemcpyHostToDevice);\n",
        "        err = cudaMemcpy(d_M, M, size1, cudaMemcpyHostToDevice);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMalloc((void **)&d_N, size2);\n",
        "          err =   cudaMalloc((void **)&d_N, size2);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMemcpy(d_N, N, size2, cudaMemcpyHostToDevice);\n",
        "          err = cudaMemcpy(d_N, N, size2, cudaMemcpyHostToDevice);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaMalloc((void **)&d_P, size3);\n",
        "          err = cudaMalloc((void **)&d_P, size3);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  \n",
        "  \n",
        "\n",
        "  dim3 dimGrid(ceil((Width2)/((float)TILE_WIDTH)), ceil(Height1/(float)TILE_WIDTH), 1);\n",
        "  dim3 dimBlock(ceil(TILE_WIDTH),TILE_WIDTH, 1);\n",
        "  clock_t start = clock();\n",
        "  MatrixMulKernel<<<dimGrid, dimBlock>>>(d_M, d_N, d_P);\n",
        "  cudaDeviceSynchronize();\n",
        "  err = cudaDeviceSynchronize();\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  clock_t stop = clock();\n",
        "  double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "  cout<<\"Time taken to complete only the Kernel computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "  cudaMemcpy(P, d_P, size3, cudaMemcpyDeviceToHost);\n",
        "  err =cudaMemcpy(P, d_P, size3, cudaMemcpyDeviceToHost);\n",
        "   if (err!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "  cudaFree(d_M); cudaFree(d_N); cudaFree (d_P);\n",
        "  }\n",
        "\n",
        "void intialize_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            //M[j+i*COLS] =rand()%256;\n",
        "             M[j+i*COLS] =j+i*COLS;\n",
        "      }\n",
        "  }\n",
        "}\n",
        "void Print_matrix(float *M,int ROWS,int COLS){\n",
        "    for(int i=0; i<ROWS;i++){\n",
        "          for(int j=0;j<COLS;j++){\n",
        "            cout<<M[j+i*COLS]<<\" \";\n",
        "      }\n",
        "      cout<<endl;\n",
        "  }   \n",
        "}\n",
        "bool validation(){\n",
        "\n",
        "  if (Width1!=Height2){\n",
        "      cout<<\"There is an error in the dims of the matrices\"<<endl; \n",
        "      return 0;\n",
        "  }\n",
        "  return 1;\n",
        "  \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    srand(time(0));\n",
        "    \n",
        "    float *M,*N,*Pout;\n",
        "    \n",
        "    \n",
        "    if (!validation())\n",
        "        return 0;\n",
        "    \n",
        "\n",
        "    M=(float*) malloc(Width1*Height1*sizeof(float));\n",
        "    N=(float*) malloc(Width2*Height2*sizeof(float));\n",
        "    Pout=(float*) malloc(Width2*Height1*sizeof(float));\n",
        "\n",
        "    intialize_matrix(M,Height1,Width1);\n",
        "    intialize_matrix(N,Height2,Width2);\n",
        "    //cout<<\"M\"<<endl;\n",
        "   // Print_matrix(M,Height1,Width1);\n",
        "   // cout<<endl;\n",
        "   // cout<<\"N\"<<endl;\n",
        "    //Print_matrix(N,Height2,Width2);\n",
        "\n",
        "    //cout<<endl;\n",
        "     clock_t start = clock();\n",
        "    MatrixMulOnDevice(M,N,Pout);\n",
        "\n",
        "    //I added code\n",
        "    cudaDeviceSynchronize();\n",
        "        cudaError_t err1 = cudaDeviceSynchronize();\n",
        "   if (err1!= cudaSuccess) {\n",
        "      printf(\"%s in %s at line %d\\n\",cudaGetErrorString(err1), __FILE__, __LINE__);\n",
        "        exit(EXIT_FAILURE);\n",
        "        }\n",
        "    clock_t stop = clock();\n",
        "    double time_spent = (double)(stop - start) / CLOCKS_PER_SEC;\n",
        "    cout<<\"Time taken to complete the entire wrapper computation is: \"<<time_spent<<\" seconds.\\n\";\n",
        "\n",
        "   // cout<<\"P\"<<endl;\n",
        " //Print_matrix(Pout,Height1,Width2);\n",
        "    //2.28394e+10 2.28395e+10\n",
        "    //5.32934e+12 5.32934e+12\n",
        "  \n",
        "\n",
        " cout<<Pout[0]<<\" \"<<Pout[1999];\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "gunyow94B7Sy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6643994-bc4f-4838-853a-944b7a3c7d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken to complete only the Kernel computation is: 0.446976 seconds.\n",
            "Time taken to complete the entire wrapper computation is: 0.759228 seconds.\n",
            "5.32934e+12 5.33333e+12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speedup for 1000x500 * 500x1000 matrices\n",
        "Speedup = Time in Sequential / Time in Parallel\n",
        "\n",
        "speedup of kernel only = 1.77262/0.053848 = 33x times speedup\n",
        "\n",
        "speedup of whole wrapper function = 1.77262/0.283998= 6x times speedup"
      ],
      "metadata": {
        "id": "GQQW1bPoH29h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Speedup for 1000x1000 matrices\n",
        "Speedup = Time in Sequential / Time in Parallel\n",
        "\n",
        "speedup of kernel only = 3.54652/0.105868 = 34x times speedup\n",
        "\n",
        "speedup of whole wrapper function = 3.54652/0.332278 = 11x times speedup"
      ],
      "metadata": {
        "id": "UZToq-bHH29n"
      }
    }
  ]
}